"""
HTML Processor Step
HTML æ–‡æ¡£å¤„ç†æ­¥éª¤
"""

from bs4 import BeautifulSoup
import html2text

from .base import ProcessingStep, ProcessingContext
from ..utils.cleaner import clean_text, clean_html_content, clean_metadata
from ..utils.code_extractor import CodeExtractor


class HTMLProcessor(ProcessingStep):
    """
    HTML å¤„ç†å™¨
    å°† HTML æ–‡æ¡£è½¬æ¢ä¸ºçº¯æ–‡æœ¬
    """
    
    def __init__(
        self,
        extract_codes: bool = True,
        content_selector: str = "div.td-content",
        code_blocks_dir: str = None,
        skip_if_missing_selector: bool = True,
        html2text_ignore_links: bool = True,
        html2text_body_width: int = 0,
    ):
        """
        åˆå§‹åŒ– HTML å¤„ç†å™¨
        
        Args:
            extract_codes: æ˜¯å¦æå–ä»£ç å—
            content_selector: ä¸»è¦å†…å®¹åŒºåŸŸçš„ CSS é€‰æ‹©å™¨
            code_blocks_dir: ä»£ç å—ä¿å­˜ç›®å½•
        """
        super().__init__("HTMLProcessor")
        self.extract_codes = extract_codes
        self.content_selector = content_selector
        self.code_extractor = CodeExtractor(code_blocks_dir) if extract_codes else None
        # If a selector is specified but not found, skip the document instead of
        # falling back to extracting the entire page.
        self.skip_if_missing_selector = skip_if_missing_selector
        # html2text config
        self.html2text_ignore_links = html2text_ignore_links
        self.html2text_body_width = html2text_body_width
    
    async def process(self, context: ProcessingContext) -> ProcessingContext:
        """
        å¤„ç† HTML æ–‡æ¡£
        
        Args:
            context: åŒ…å«æ–‡æ¡£çš„å¤„ç†ä¸Šä¸‹æ–‡
            
        Returns:
            ProcessingContext: æ–‡æ¡£å†…å®¹å·²è½¬æ¢ä¸ºçº¯æ–‡æœ¬
        """
        self.logger.info(f"ðŸ”„ Processing {len(context.documents)} HTML documents...")
        
        processed_count = 0
        skipped_missing_selector = 0
        skipped_paths = []
        for doc in context.documents:
            try:
                # åªå¤„ç† HTML æ–‡ä»¶
                file_type = doc.get("metadata", {}).get("file_type", "")
                if file_type not in [".html", ".htm"]:
                    continue
                
                # å¤„ç† HTML å†…å®¹
                processed_content, extracted_codes, used_selector = self._process_html(doc["content"])
                if self.skip_if_missing_selector and self.content_selector and not used_selector:
                    skipped_missing_selector += 1
                    rel_path = doc.get("metadata", {}).get("relative_path") or doc.get("file_path", "unknown")
                    skipped_paths.append(rel_path)
                    # Mark as empty so downstream steps naturally ignore it
                    doc["content"] = ""
                    continue
                doc["content"] = processed_content
                
                # æ›´æ–°å…ƒæ•°æ®
                if extracted_codes:
                    doc["metadata"]["extracted_codes"] = extracted_codes
                    doc["metadata"]["code_blocks_count"] = len(extracted_codes)
                
                # æ¸…ç†å…ƒæ•°æ®
                doc["metadata"] = clean_metadata(doc["metadata"])
                
                processed_count += 1
                
            except Exception as e:
                context.add_error(
                    f"Failed to process HTML {doc.get('file_path', 'unknown')}: {str(e)}"
                )
        
        self.logger.info(f"âœ… Processed {processed_count} HTML documents")
        if skipped_missing_selector:
            self.logger.warning(
                f"âš ï¸ Skipped {skipped_missing_selector} documents missing selector: {self.content_selector}"
            )
            # Log a small sample to avoid overly noisy logs
            for p in skipped_paths[:50]:
                self.logger.warning(f"   - missing selector, skipped: {p}")
        return context
    
    def _process_html(self, html_content: str) -> tuple:
        """
        å¤„ç†å•ä¸ª HTML å†…å®¹
        
        Args:
            html_content: HTML å†…å®¹
            
        Returns:
            tuple: (å¤„ç†åŽçš„æ–‡æœ¬, æå–çš„ä»£ç å—åˆ—è¡¨, æ˜¯å¦æˆåŠŸä½¿ç”¨ content_selector)
        """
        if not html_content:
            return "", [], False
        
        # æ¸…ç† HTML
        cleaned_html = clean_html_content(html_content)
        
        # æå–ä»£ç å—
        extracted_codes = []
        if self.code_extractor:
            cleaned_html, extracted_codes = self.code_extractor.extract_code_blocks(cleaned_html)
        
        # è§£æž HTML
        soup = BeautifulSoup(cleaned_html, "html.parser")
        
        # å°è¯•æ‰¾åˆ°ä¸»è¦å†…å®¹åŒºåŸŸ
        content_div = None
        if self.content_selector:
            # è§£æžé€‰æ‹©å™¨
            parts = self.content_selector.split(".")
            tag_name = parts[0] if parts[0] else "div"
            class_name = parts[1] if len(parts) > 1 else None
            
            if class_name:
                content_div = soup.find(tag_name, class_=class_name)
            else:
                content_div = soup.find(tag_name)
        
        # æå–æ–‡æœ¬
        used_selector = content_div is not None
        html_fragment = str(content_div) if content_div is not None else str(soup)
        text = self._html_to_text(html_fragment)
        
        # æ¸…ç†æ–‡æœ¬
        text = clean_text(text)
        
        return text, extracted_codes, used_selector

    def _html_to_text(self, html: str) -> str:
        """
        Convert HTML to markdown-ish text using html2text.

        We intentionally avoid extra manual post-processing here to preserve hierarchy
        (lists/tables/headings) as best as html2text can.
        """
        h = html2text.HTML2Text()
        h.ignore_links = self.html2text_ignore_links
        # 0 means no wrapping (avoid hard-wrapping that creates artificial newlines)
        h.body_width = int(self.html2text_body_width) if self.html2text_body_width is not None else 0
        # Prefer keeping structure
        h.ignore_images = True
        try:
            h.ignore_tables = False
        except Exception:
            pass
        return h.handle(html or "")

    # Note: previous versions contained manual newline/table heuristics here.
    # We intentionally removed them and rely on html2text to preserve structure.

