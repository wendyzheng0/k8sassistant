"""
Embedding Step
å‘é‡åŒ–æ­¥éª¤
"""

import sys
import os
from typing import List, Optional

# Ensure project root is in path
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from .base import ProcessingStep, ProcessingContext, DocumentChunk


class EmbeddingStep(ProcessingStep):
    """
    å‘é‡åŒ–æ­¥éª¤
    ä½¿ç”¨ embedding æ¨¡å‹å°†æ–‡æœ¬å—è½¬æ¢ä¸ºå‘é‡
    """
    
    def __init__(
        self,
        batch_size: int = 32,
        embedding_service=None,
    ):
        """
        åˆå§‹åŒ–å‘é‡åŒ–æ­¥éª¤
        
        Args:
            batch_size: æ‰¹å¤„ç†å¤§å°
            embedding_service: å¯é€‰çš„ embedding æœåŠ¡å®ä¾‹
        """
        super().__init__("EmbeddingStep")
        self.batch_size = batch_size
        self._embedding_service = embedding_service
        self._initialized = False
    
    async def _ensure_initialized(self):
        """ç¡®ä¿ embedding æœåŠ¡å·²åˆå§‹åŒ–"""
        if self._initialized:
            return
        
        if self._embedding_service is None:
            try:
                from shared.embeddings import create_embedding_service
                self._embedding_service = create_embedding_service(use_singleton=True)
                self.logger.info(
                    f"âœ… Embedding service initialized: "
                    f"{self._embedding_service.get_model_info()}"
                )
            except Exception as e:
                self.logger.error(f"Failed to initialize embedding service: {e}")
                raise
        
        self._initialized = True
    
    async def process(self, context: ProcessingContext) -> ProcessingContext:
        """
        å‘é‡åŒ–å¤„ç†
        
        Args:
            context: åŒ…å«æ–‡æœ¬å—çš„å¤„ç†ä¸Šä¸‹æ–‡
            
        Returns:
            ProcessingContext: æ–‡æœ¬å—å·²åŒ…å«å‘é‡
        """
        await self._ensure_initialized()
        
        chunks = context.chunks
        if not chunks:
            self.logger.warning("âš ï¸ No chunks to embed")
            return context
        
        self.logger.info(f"ğŸ”„ Embedding {len(chunks)} chunks (batch_size={self.batch_size})...")
        
        # æ‰¹é‡å¤„ç†
        total_embedded = 0
        for i in range(0, len(chunks), self.batch_size):
            batch = chunks[i:i + self.batch_size]
            texts = [chunk.content for chunk in batch]
            
            try:
                # è°ƒç”¨ embedding æœåŠ¡
                embeddings = self._embedding_service.encode_batch(texts, batch_size=self.batch_size)
                
                # å°†å‘é‡èµ‹å€¼ç»™å—
                for chunk, embedding in zip(batch, embeddings):
                    chunk.embedding = embedding.tolist() if hasattr(embedding, 'tolist') else list(embedding)
                
                total_embedded += len(batch)
                
                if total_embedded % 100 == 0 or total_embedded == len(chunks):
                    self.logger.info(f"   Embedded {total_embedded}/{len(chunks)} chunks")
                    
            except Exception as e:
                context.add_error(f"Embedding failed for batch {i//self.batch_size}: {str(e)}")
        
        self.logger.info(f"âœ… Embedded {total_embedded} chunks")
        return context
    
    def get_embedding_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        if self._embedding_service is None:
            from shared.embeddings import create_embedding_service
            self._embedding_service = create_embedding_service(use_singleton=True)
            self._initialized = True
        return self._embedding_service.get_embedding_dimension()

