"""
Processing Step Base Classes
å¤„ç†æ­¥éª¤åŸºç±»å®šä¹‰
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, AsyncIterator
import uuid
import logging


logger = logging.getLogger(__name__)


@dataclass
class DocumentChunk:
    """
    æ–‡æ¡£å—æ•°æ®ç»“æ„
    è¡¨ç¤ºä¸€ä¸ªç»è¿‡å¤„ç†çš„æ–‡æœ¬å—
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    content: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    embedding: Optional[List[float]] = None
    
    @property
    def is_valid(self) -> bool:
        """æ£€æŸ¥å—æ˜¯å¦æœ‰æ•ˆ"""
        return bool(self.content and len(self.content.strip()) >= 10)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        result = {
            "id": self.id,
            "content": self.content,
            "metadata": self.metadata,
        }
        if self.embedding is not None:
            result["embedding"] = self.embedding
        return result


@dataclass
class ProcessingContext:
    """
    å¤„ç†ä¸Šä¸‹æ–‡
    åœ¨æµæ°´çº¿å„æ­¥éª¤é—´ä¼ é€’æ•°æ®å’ŒçŠ¶æ€
    """
    # åŸå§‹æ•°æ®ç›®å½•
    data_dir: str = ""
    
    # å·²è¯»å–çš„æ–‡æ¡£åˆ—è¡¨ (file_path, content, metadata)
    documents: List[Dict[str, Any]] = field(default_factory=list)
    
    # å¤„ç†åçš„æ–‡æœ¬å—
    chunks: List[DocumentChunk] = field(default_factory=list)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats: Dict[str, int] = field(default_factory=lambda: {
        "files_read": 0,
        "files_skipped": 0,
        "chunks_created": 0,
        "chunks_stored": 0,
        "errors": 0,
    })
    
    # é”™è¯¯ä¿¡æ¯
    errors: List[str] = field(default_factory=list)
    
    def add_document(self, file_path: str, content: str, metadata: Dict[str, Any] = None):
        """æ·»åŠ æ–‡æ¡£"""
        self.documents.append({
            "file_path": file_path,
            "content": content,
            "metadata": metadata or {},
        })
        self.stats["files_read"] += 1
    
    def add_chunk(self, chunk: DocumentChunk):
        """æ·»åŠ æ–‡æœ¬å—"""
        self.chunks.append(chunk)
        self.stats["chunks_created"] += 1
    
    def add_error(self, error: str):
        """æ·»åŠ é”™è¯¯ä¿¡æ¯"""
        self.errors.append(error)
        self.stats["errors"] += 1
        logger.error(error)
    
    def get_summary(self) -> str:
        """è·å–å¤„ç†æ‘˜è¦"""
        return (
            f"ğŸ“Š Processing Summary:\n"
            f"   Files Read: {self.stats['files_read']}\n"
            f"   Files Skipped: {self.stats['files_skipped']}\n"
            f"   Chunks Created: {self.stats['chunks_created']}\n"
            f"   Chunks Stored: {self.stats['chunks_stored']}\n"
            f"   Errors: {self.stats['errors']}"
        )


class ProcessingStep(ABC):
    """
    å¤„ç†æ­¥éª¤åŸºç±»
    æ‰€æœ‰å¤„ç†æ­¥éª¤éƒ½åº”ç»§æ‰¿æ­¤ç±»
    """
    
    def __init__(self, name: str = None):
        self.name = name or self.__class__.__name__
        self.logger = logging.getLogger(f"processors.{self.name}")
    
    @abstractmethod
    async def process(self, context: ProcessingContext) -> ProcessingContext:
        """
        å¤„ç†æ•°æ®
        
        Args:
            context: å¤„ç†ä¸Šä¸‹æ–‡
            
        Returns:
            ProcessingContext: æ›´æ–°åçš„ä¸Šä¸‹æ–‡
        """
        pass
    
    async def __call__(self, context: ProcessingContext) -> ProcessingContext:
        """ä½¿æ­¥éª¤å¯è°ƒç”¨"""
        self.logger.info(f"ğŸ”„ Starting {self.name}...")
        try:
            result = await self.process(context)
            self.logger.info(f"âœ… {self.name} completed")
            return result
        except Exception as e:
            context.add_error(f"{self.name} failed: {str(e)}")
            raise


class CompositeStep(ProcessingStep):
    """
    ç»„åˆæ­¥éª¤
    å°†å¤šä¸ªæ­¥éª¤ç»„åˆæˆä¸€ä¸ª
    """
    
    def __init__(self, steps: List[ProcessingStep], name: str = "CompositeStep"):
        super().__init__(name)
        self.steps = steps
    
    async def process(self, context: ProcessingContext) -> ProcessingContext:
        """ä¾æ¬¡æ‰§è¡Œæ‰€æœ‰æ­¥éª¤"""
        for step in self.steps:
            context = await step(context)
        return context

