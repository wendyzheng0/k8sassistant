#!/usr/bin/env python3
"""
æ•°æ®æ¸…ç†å·¥å…·æ¨¡å—
ç”¨äºæ¸…ç†å’ŒéªŒè¯èŠ‚ç‚¹æ•°æ®ï¼Œé¿å…æ•°æ®ç±»å‹é”™è¯¯
"""

import re
from typing import List, Any, Dict, Union
from llama_index.core import Document
from bs4 import BeautifulSoup
from code_extractor import CodeExtractor
    


def clean_text(text: Any) -> str:
    """
    æ¸…ç†æ–‡æœ¬æ•°æ®ï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„å­—ç¬¦ä¸²
    
    Args:
        text: åŸå§‹æ–‡æœ¬æ•°æ®
        
    Returns:
        str: æ¸…ç†åçš„å­—ç¬¦ä¸²
    """
    if text is None:
        return ""
    
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    if not isinstance(text, str):
        text = str(text)
    
    # ç§»é™¤æ§åˆ¶å­—ç¬¦å’Œç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', text)
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)
    
    # å»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    
    return text


def clean_metadata(metadata: Dict[str, Any]) -> Dict[str, Union[str, int, float, bool]]:
    """
    æ¸…ç†å…ƒæ•°æ®ï¼Œç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ”¯æŒçš„æ•°æ®ç±»å‹
    
    Args:
        metadata: åŸå§‹å…ƒæ•°æ®å­—å…¸
        
    Returns:
        Dict: æ¸…ç†åçš„å…ƒæ•°æ®å­—å…¸
    """
    if not metadata:
        return {}
    
    cleaned_metadata = {}
    
    for key, value in metadata.items():
        # ç¡®ä¿keyæ˜¯å­—ç¬¦ä¸²
        if not isinstance(key, str):
            key = str(key)
        
        # æ¸…ç†keyï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
        key = re.sub(r'[^\w\-_.]', '_', key)
        
        # å¤„ç†value
        if value is None:
            cleaned_metadata[key] = ""
        elif isinstance(value, str):
            cleaned_metadata[key] = clean_text(value)
        elif isinstance(value, (int, float, bool)):
            cleaned_metadata[key] = value
        elif isinstance(value, (list, tuple)):
            # å°†åˆ—è¡¨/å…ƒç»„è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            cleaned_metadata[key] = str(value)
        else:
            # å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            cleaned_metadata[key] = clean_text(str(value))
    
    return cleaned_metadata


def validate_node_text(text: str, min_length: int = 10) -> bool:
    """
    éªŒè¯èŠ‚ç‚¹æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        text: æ–‡æœ¬å†…å®¹
        min_length: æœ€å°é•¿åº¦è¦æ±‚
        
    Returns:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    if not text or not isinstance(text, str):
        return False
    
    # æ£€æŸ¥é•¿åº¦
    if len(text.strip()) < min_length:
        return False
    
    # æ£€æŸ¥æ˜¯å¦åªåŒ…å«ç©ºç™½å­—ç¬¦
    if not text.strip():
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆå†…å®¹ï¼ˆè‡³å°‘åŒ…å«å­—æ¯æˆ–æ•°å­—ï¼‰
    if not re.search(r'[a-zA-Z0-9\u4e00-\u9fff]', text):
        return False
    
    return True


def clean_document(doc: Document) -> Document:
    """
    æ¸…ç†æ–‡æ¡£æ•°æ®
    
    Args:
        doc: åŸå§‹æ–‡æ¡£å¯¹è±¡
        
    Returns:
        Document: æ¸…ç†åçš„æ–‡æ¡£å¯¹è±¡
    """
    # æ¸…ç†æ–‡æœ¬
    cleaned_text = clean_text(doc.text)
    
    # æ¸…ç†å…ƒæ•°æ®
    cleaned_metadata = clean_metadata(doc.metadata)
    
    # åˆ›å»ºæ–°çš„æ–‡æ¡£å¯¹è±¡
    return Document(text=cleaned_text, metadata=cleaned_metadata)


def clean_node(node: Any) -> Any:
    """
    æ¸…ç†èŠ‚ç‚¹æ•°æ®
    
    Args:
        node: åŸå§‹èŠ‚ç‚¹å¯¹è±¡
        
    Returns:
        æ¸…ç†åçš„èŠ‚ç‚¹å¯¹è±¡
    """
    try:
        # æ¸…ç†æ–‡æœ¬
        if hasattr(node, 'text') and node.text is not None:
            node.text = clean_text(node.text)
        
        # æ¸…ç†å…ƒæ•°æ®
        if hasattr(node, 'metadata') and node.metadata is not None:
            node.metadata = clean_metadata(node.metadata)
        
        return node
        
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†èŠ‚ç‚¹æ—¶å‡ºé”™: {e}")
        return node


def validate_node(node: Any, min_text_length: int = 10) -> bool:
    """
    éªŒè¯èŠ‚ç‚¹æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        node: èŠ‚ç‚¹å¯¹è±¡
        min_text_length: æœ€å°æ–‡æœ¬é•¿åº¦
        
    Returns:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰textå±æ€§
        if not hasattr(node, 'text'):
            return False
        
        # éªŒè¯æ–‡æœ¬
        if not validate_node_text(node.text, min_text_length):
            return False
        
        return True
        
    except Exception as e:
        print(f"âš ï¸ éªŒè¯èŠ‚ç‚¹æ—¶å‡ºé”™: {e}")
        return False


def clean_and_validate_nodes(nodes: List[Any], min_text_length: int = 10) -> List[Any]:
    """
    æ¸…ç†å’ŒéªŒè¯èŠ‚ç‚¹åˆ—è¡¨ï¼Œå¹¶å…³è”ä»£ç å—
    
    Args:
        nodes: åŸå§‹èŠ‚ç‚¹åˆ—è¡¨
        min_text_length: æœ€å°æ–‡æœ¬é•¿åº¦
        
    Returns:
        List: æ¸…ç†å’ŒéªŒè¯åçš„æœ‰æ•ˆèŠ‚ç‚¹åˆ—è¡¨
    """
    print(f"ğŸ” æ¸…ç†å’ŒéªŒè¯ {len(nodes)} ä¸ªèŠ‚ç‚¹...")
    
    valid_nodes = []
    skipped_count = 0
    
    for i, node in enumerate(nodes):
        try:
            # æ¸…ç†èŠ‚ç‚¹
            cleaned_node = clean_node(node)
            
            # å…³è”ä»£ç å—åˆ°èŠ‚ç‚¹
            cleaned_node = associate_codes_with_node(cleaned_node)
            
            # éªŒè¯èŠ‚ç‚¹
            if validate_node(cleaned_node, min_text_length):
                valid_nodes.append(cleaned_node)
            else:
                skipped_count += 1
                if skipped_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªè·³è¿‡çš„èŠ‚ç‚¹
                    print(f"âš ï¸ è·³è¿‡èŠ‚ç‚¹ {i}: æ–‡æœ¬æ— æ•ˆæˆ–å¤ªçŸ­")
                
        except Exception as e:
            skipped_count += 1
            print(f"âš ï¸ å¤„ç†èŠ‚ç‚¹ {i} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"âœ… æ¸…ç†å®Œæˆ: {len(valid_nodes)}/{len(nodes)} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹")
    if skipped_count > 5:
        print(f"   è·³è¿‡äº† {skipped_count} ä¸ªæ— æ•ˆèŠ‚ç‚¹")
    
    return valid_nodes


def associate_codes_with_node(node: Any) -> Any:
    """
    å°†ä»£ç å—å…³è”åˆ°èŠ‚ç‚¹
    
    Args:
        node: èŠ‚ç‚¹å¯¹è±¡
        
    Returns:
        å…³è”äº†ä»£ç å—çš„èŠ‚ç‚¹å¯¹è±¡
    """
    if not hasattr(node, 'metadata') or not node.metadata:
        return node
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æå–çš„ä»£ç å—
    extracted_codes = node.metadata.get('extracted_codes', [])
    if not extracted_codes:
        return node
    
    # åˆå§‹åŒ–èŠ‚ç‚¹çš„ä»£ç å—åˆ—è¡¨
    if 'code_blocks' not in node.metadata:
        node.metadata['code_blocks'] = []
    
    # æ£€æŸ¥èŠ‚ç‚¹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä»£ç å—å ä½ç¬¦
    node_text = getattr(node, 'text', '')
    if not node_text:
        return node
    
    # æŸ¥æ‰¾èŠ‚ç‚¹ä¸­çš„ä»£ç å—å ä½ç¬¦
    import re
    placeholder_pattern = r'\[CODE_BLOCK:([^:]+)\]'
    matches = re.findall(placeholder_pattern, node_text)
    
    for code_id in matches:
        # æŸ¥æ‰¾å¯¹åº”çš„ä»£ç å—
        code_block = None
        for code in extracted_codes:
            # ç¡®ä¿codeæ˜¯å­—å…¸ç±»å‹
            if isinstance(code, dict) and code.get('id') == code_id:
                code_block = code
                break
        
        if code_block:
            # å°†ä»£ç å—æ·»åŠ åˆ°èŠ‚ç‚¹çš„å…ƒæ•°æ®ä¸­
            node.metadata['code_blocks'].append({
                'id': code_block.get('id', code_id),
                # 'content': code_block.get('content', ''),
                # 'language': code_block.get('language', ''),
                'length': code_block.get('length', 0),
                # 'preview': preview
            })
            
            # ä»èŠ‚ç‚¹æ–‡æœ¬ä¸­ç§»é™¤å ä½ç¬¦ï¼Œæ›¿æ¢ä¸ºç®€çŸ­çš„æ ‡è®°
            placeholder = f"[CODE_BLOCK:{code_id}]"
            # node.text = node.text.replace(placeholder, f"[ä»£ç ç¤ºä¾‹: {code_block.get('language', 'unknown')}]")
    
    # ç§»é™¤å·²å¤„ç†çš„ä»£ç å—æå–ä¿¡æ¯
    if 'extracted_codes' in node.metadata:
        del node.metadata['extracted_codes']

    return node


def clean_html_content(html_content: str) -> str:
    """
    æ¸…ç†HTMLå†…å®¹
    
    Args:
        html_content: åŸå§‹HTMLå†…å®¹
        
    Returns:
        str: æ¸…ç†åçš„HTMLå†…å®¹
    """
    if not html_content or not isinstance(html_content, str):
        return ""
    
    # ç§»é™¤HTMLæ³¨é‡Š
    html_content = re.sub(r'<!--.*?-->', '', html_content, flags=re.DOTALL)
    
    # ç§»é™¤scriptå’Œstyleæ ‡ç­¾åŠå…¶å†…å®¹
    html_content = re.sub(r'<(script|style)[^>]*>.*?</\1>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
    
    # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
    html_content = re.sub(r'\s+', ' ', html_content)
    
    # å»é™¤é¦–å°¾ç©ºç™½
    html_content = html_content.strip()
    
    return html_content
