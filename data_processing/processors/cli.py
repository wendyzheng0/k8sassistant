#!/usr/bin/env python3
"""
CLI Entry Point
ç»Ÿä¸€å‘½ä»¤è¡Œå…¥å£
"""

import os
import sys
import argparse
import asyncio
from pathlib import Path

# Ensure project root is in path
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="K8s Assistant æ–‡æ¡£å¤„ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨ Milvus å­˜å‚¨
  python -m data_processing.processors.cli --data-dir ./data/zh-cn --backend milvus

  # ä½¿ç”¨ Elasticsearch å­˜å‚¨
  python -m data_processing.processors.cli --data-dir ./data/zh-cn --backend elasticsearch

  # è‡ªå®šä¹‰åˆ†å—å¤§å°
  python -m data_processing.processors.cli --data-dir ./data/zh-cn --chunk-size 512 --chunk-overlap 50
        """
    )
    
    # æ•°æ®æºé…ç½®
    parser.add_argument(
        "--data-dir", "-d",
        type=str,
        default=None,
        help="æ–‡æ¡£æ•°æ®ç›®å½•è·¯å¾„ (é»˜è®¤: ./data/zh-cn)"
    )
    
    # å­˜å‚¨åç«¯é…ç½®
    parser.add_argument(
        "--backend", "-b",
        type=str,
        choices=["milvus", "elasticsearch"],
        default="milvus",
        help="å­˜å‚¨åç«¯ç±»å‹ (é»˜è®¤: milvus)"
    )
    
    # Milvus é…ç½®
    parser.add_argument(
        "--milvus-uri",
        type=str,
        default=None,
        help="Milvus æœåŠ¡åœ°å€ (é»˜è®¤: http://localhost:19530)"
    )
    parser.add_argument(
        "--collection-name",
        type=str,
        default=None,
        help="Milvus é›†åˆåç§° (é»˜è®¤: k8s_docs)"
    )
    parser.add_argument(
        "--no-overwrite",
        action="store_true",
        help="ä¸è¦†ç›–å·²å­˜åœ¨çš„é›†åˆ"
    )
    
    # Elasticsearch é…ç½®
    parser.add_argument(
        "--es-host",
        type=str,
        default=None,
        help="Elasticsearch æœåŠ¡åœ°å€ (é»˜è®¤: http://localhost:9200)"
    )
    parser.add_argument(
        "--es-index",
        type=str,
        default=None,
        help="Elasticsearch ç´¢å¼•åç§° (é»˜è®¤: k8s-docs)"
    )
    
    # æ–‡æœ¬å¤„ç†é…ç½®
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=None,
        help="æ–‡æœ¬å—å¤§å° (é»˜è®¤: 1024)"
    )
    parser.add_argument(
        "--chunk-overlap",
        type=int,
        default=None,
        help="æ–‡æœ¬å—é‡å å¤§å° (é»˜è®¤: 100)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=None,
        help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 32)"
    )
    
    # å…¶ä»–é…ç½®
    parser.add_argument(
        "--log-level",
        type=str,
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="è¯•è¿è¡Œæ¨¡å¼ï¼Œåªè¯»å–å’Œå¤„ç†æ–‡æ¡£ï¼Œä¸å­˜å‚¨"
    )
    
    return parser


async def main_async(args: argparse.Namespace) -> int:
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    import logging
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    from .runner import PipelineRunner
    from .config import ProcessorSettings
    
    # æ„å»ºé…ç½®å‚æ•°
    config_kwargs = {}
    
    if args.data_dir:
        config_kwargs["data_dir"] = args.data_dir
    if args.backend:
        config_kwargs["storage_backend"] = args.backend
    if args.milvus_uri:
        config_kwargs["milvus_uri"] = args.milvus_uri
    if args.collection_name:
        config_kwargs["collection_name"] = args.collection_name
    if args.no_overwrite:
        config_kwargs["milvus_overwrite"] = False
    if args.es_host:
        config_kwargs["es_host"] = args.es_host
    if args.es_index:
        config_kwargs["es_index"] = args.es_index
    if args.chunk_size:
        config_kwargs["chunk_size"] = args.chunk_size
    if args.chunk_overlap:
        config_kwargs["chunk_overlap"] = args.chunk_overlap
    if args.batch_size:
        config_kwargs["batch_size"] = args.batch_size
    if args.log_level:
        config_kwargs["log_level"] = args.log_level
    
    try:
        # åˆ›å»ºé…ç½®
        settings = ProcessorSettings(**config_kwargs)
        
        # éªŒè¯æ•°æ®ç›®å½•
        if not os.path.exists(settings.data_dir):
            print(f"âŒ Error: Data directory does not exist: {settings.data_dir}")
            return 1
        
        print("=" * 60)
        print("ğŸš€ K8s Assistant Document Processor")
        print("=" * 60)
        
        if args.dry_run:
            print("âš ï¸  DRY RUN MODE - Documents will not be stored")
        
        # è¿è¡Œæµæ°´çº¿
        runner = PipelineRunner(settings)
        result = await runner.run()
        
        # æ‰“å°ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“Š Processing Result")
        print("=" * 60)
        print(result)
        
        if result.errors:
            print("\nâš ï¸  Errors encountered:")
            for i, error in enumerate(result.errors[:10], 1):
                print(f"   {i}. {error}")
            if len(result.errors) > 10:
                print(f"   ... and {len(result.errors) - 10} more errors")
        
        return 0 if result.success else 1
        
    except KeyboardInterrupt:
        print("\nâš ï¸  Interrupted by user")
        return 130
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1


def main() -> int:
    """ä¸»å‡½æ•°å…¥å£"""
    parser = create_parser()
    args = parser.parse_args()
    return asyncio.run(main_async(args))


if __name__ == "__main__":
    sys.exit(main())

