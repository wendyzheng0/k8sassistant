"""
å¤§è¯­è¨€æ¨¡å‹æœåŠ¡
"""

import asyncio
from typing import List, Dict, Any, Optional
import openai
from app.core.config import settings
from app.core.logging import get_logger


class LLMService:
    """å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ç±»"""
    
    def __init__(self):
        self.logger = get_logger("LLMService")
        self.api_key = settings.LLM_API_KEY
        self.base_url = settings.LLM_BASE_URL
        self.model = settings.LLM_MODEL
        self.max_tokens = settings.MAX_TOKENS
        self.temperature = settings.TEMPERATURE
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.client = openai.AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
    
    async def generate_response(
        self,
        messages: List[Dict[str, str]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        stream: bool = False
    ) -> str:
        """
        ç”Ÿæˆå›å¤
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§tokenæ•°
            stream: æ˜¯å¦æµå¼è¾“å‡º
            
        Returns:
            ç”Ÿæˆçš„å›å¤æ–‡æœ¬
        """
        try:
            # ä½¿ç”¨é»˜è®¤å‚æ•°æˆ–ä¼ å…¥çš„å‚æ•°
            temp = temperature if temperature is not None else self.temperature
            max_toks = max_tokens if max_tokens is not None else self.max_tokens
            
            self.logger.info(f"ğŸ¤– å¼€å§‹ç”Ÿæˆå›å¤ï¼Œæ¨¡å‹: {self.model}")
            
            if stream:
                return await self._generate_stream_response(messages, temp, max_toks)
            else:
                return await self._generate_sync_response(messages, temp, max_toks)
                
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            raise
    
    async def _generate_sync_response(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int
    ) -> str:
        """åŒæ­¥ç”Ÿæˆå›å¤"""
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            content = response.choices[0].message.content
            self.logger.info(f"âœ… å›å¤ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(content)}")
            return content
            
        except Exception as e:
            self.logger.error(f"âŒ åŒæ­¥ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            raise
    
    async def _generate_stream_response(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int
    ):
        """æµå¼ç”Ÿæˆå›å¤"""
        try:
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            self.logger.error(f"âŒ æµå¼ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            raise
    
    async def generate_rag_response(
        self,
        query: str,
        context_docs: List[Dict[str, Any]],
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """
        åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆå›å¤
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context_docs: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£
            conversation_history: å¯¹è¯å†å²
            
        Returns:
            ç”Ÿæˆçš„å›å¤
        """
        try:
            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = self._build_system_prompt()
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context_text = self._build_context_text(context_docs)
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯
            user_message = self._build_user_message(query, context_text)
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ å¯¹è¯å†å²
            if conversation_history:
                messages.extend(conversation_history)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": user_message})
            
            # ç”Ÿæˆå›å¤
            response = await self.generate_response(messages)
            
            return response
            
        except Exception as e:
            self.logger.error(f"âŒ RAG å›å¤ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤º"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Kubernetes åŠ©æ‰‹ï¼ŒåŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. åªèƒ½åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼Œç»å¯¹ä¸èƒ½ä½¿ç”¨ä½ è‡ªèº«çš„çŸ¥è¯†æˆ–ç»éªŒ
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä½ å¿…é¡»æ˜ç¡®å›å¤ï¼š"å¾ˆæŠ±æ­‰ï¼Œæ–‡æ¡£é‡Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. ä¸è¦å°è¯•æ¨æµ‹ã€æ¨ç†æˆ–æä¾›ä»»ä½•ä¸åœ¨æ–‡æ¡£ä¸­çš„ä¿¡æ¯
4. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€å®ç”¨ï¼Œä¸”å¿…é¡»æ¥æºäºæä¾›çš„æ–‡æ¡£
5. å¦‚æœæ¶‰åŠä»£ç ç¤ºä¾‹ï¼Œè¯·æä¾›å®Œæ•´çš„ YAML æˆ–å‘½ä»¤è¡Œç¤ºä¾‹ï¼ˆä»…é™æ–‡æ¡£ä¸­å­˜åœ¨çš„ï¼‰
6. ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œé™¤éç”¨æˆ·ç‰¹åˆ«è¦æ±‚ä½¿ç”¨è‹±æ–‡
7. å¦‚æœé—®é¢˜æ¶‰åŠå¤šä¸ªæ–¹é¢ï¼Œè¯·åˆ†ç‚¹è¯´æ˜ï¼ˆä»…é™æ–‡æ¡£ä¸­æ¶µç›–çš„æ–¹é¢ï¼‰
8. åœ¨å›ç­”æœ«å°¾å¯ä»¥æ¨èç›¸å…³çš„æ–‡æ¡£é“¾æ¥ï¼ˆå¦‚æœæ–‡æ¡£ä¸­æœ‰æä¾›ï¼‰

é‡è¦æé†’ï¼šå½“æ–‡æ¡£å†…å®¹ä¸è¶³ä»¥å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ï¼Œè¯·ç›´æ¥å›å¤"å¾ˆæŠ±æ­‰ï¼Œæ–‡æ¡£é‡Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"ï¼Œä¸è¦å°è¯•è¡¥å……ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚

è¯·å¼€å§‹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""
    
    def _build_context_text(self, context_docs: List[Dict[str, Any]]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡æ–‡æœ¬ï¼Œæ¢å¤ä»£ç å—"""
        if not context_docs:
            return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£å†…å®¹ã€‚"
        
        context_parts = []
        for i, doc in enumerate(context_docs, 1):
            title = doc.get("title", f"æ–‡æ¡£ {i}")
            file_path = doc.get("file_path", f"æ–‡æ¡£ {i}")
            # doc_id = doc.get("doc_id", f"unknown")
            content = doc.get("content", "")
            url = doc.get("url", "")
            score = doc.get("score", 0)
            metadata = doc.get("metadata", {})
            
            # æ¢å¤ä»£ç å—
            restored_content = self._restore_code_blocks(content, metadata)
            
            context_part = f"æ–‡æ¡£ {i}: {file_path}\n"
            context_part += f"ç›¸å…³åº¦: {score:.3f}\n"
            if url:
                context_part += f"æ¥æº: {url}\n"
            context_part += f"å†…å®¹: {restored_content}\n"
            context_part += "-" * 50
            
            context_parts.append(context_part)
        
        return "\n\n".join(context_parts)
    
    def _restore_code_blocks(self, content: str, metadata: Dict[str, Any]) -> str:
        """
        æ¢å¤æ–‡æ¡£ä¸­çš„ä»£ç å—
        
        Args:
            content: æ–‡æ¡£å†…å®¹
            metadata: æ–‡æ¡£å…ƒæ•°æ®
            
        Returns:
            æ¢å¤ä»£ç å—åçš„å†…å®¹
        """
        if not content or not metadata:
            return content
        
        # è·å–ä»£ç å—ä¿¡æ¯
        code_blocks = metadata.get('code_blocks', [])
        if not code_blocks:
            return content
        
        restored_content = content
        
        # æŸ¥æ‰¾å¹¶æ›¿æ¢ä»£ç æ ‡è®°
        import re
        code_marker_pattern = r'\[ä»£ç ç¤ºä¾‹:\s*([^\]]+)\]'
        
        def replace_code_marker(match):
            language = match.group(1)
            # æŸ¥æ‰¾å¯¹åº”çš„ä»£ç å—
            for code_block in code_blocks:
                if code_block.get('language') == language:
                    code_content = code_block.get('content', '')
                    if code_content:
                        return f"\n```{language}\n{code_content}\n```\n"
            return match.group(0)  # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„ä»£ç å—ï¼Œä¿æŒåŸæ ·
        
        restored_content = re.sub(code_marker_pattern, replace_code_marker, restored_content)
        
        return restored_content
    
    def _build_user_message(self, query: str, context_text: str) -> str:
        """æ„å»ºç”¨æˆ·æ¶ˆæ¯"""
        return f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

{context_text}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚"""
    
    async def test_connection(self) -> bool:
        """æµ‹è¯• LLM è¿æ¥"""
        try:
            test_message = [{"role": "user", "content": "Hello"}]
            response = await self.generate_response(test_message, max_tokens=10)
            self.logger.info("âœ… LLM è¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ LLM è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "model": self.model,
            "base_url": self.base_url,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }
