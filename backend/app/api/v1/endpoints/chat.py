"""
èŠå¤© API ç«¯ç‚¹
"""

import uuid
from datetime import datetime
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Request
from fastapi.responses import StreamingResponse

from app.models.chat import (
    ChatRequest, ChatResponse, ChatHistoryResponse,
    Conversation, ChatMessage, MessageRole, MessageType
)
from app.services.milvus_service import MilvusService
from app.services.embedding_service import EmbeddingService
from app.services.llm_service import LLMService
from app.services.complex_retrieval_service import ComplexRetrievalService
from app.core.logging import get_logger

router = APIRouter()
logger = get_logger("ChatAPI")


def get_milvus_service(request: Request) -> MilvusService:
    """è·å– Milvus æœåŠ¡å®ä¾‹"""
    return request.app.state.milvus_service


def get_embedding_service(request: Request) -> EmbeddingService:
    """è·å–åµŒå…¥æœåŠ¡å®ä¾‹"""
    return request.app.state.embedding_service


def get_llm_service(request: Request) -> LLMService:
    """è·å– LLM æœåŠ¡å®ä¾‹"""
    return request.app.state.llm_service


def get_complex_retrieval_service(request: Request) -> ComplexRetrievalService:
    """è·å–å¤æ‚æ£€ç´¢æœåŠ¡å®ä¾‹"""
    return request.app.state.complex_retrieval_service



@router.post("", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    complex_retrieval_service: ComplexRetrievalService = Depends(get_complex_retrieval_service),
    llm_service: LLMService = Depends(get_llm_service)
):
    """
    å‘é€èŠå¤©æ¶ˆæ¯å¹¶è·å–å›å¤
    """
    try:
        logger.info(f"ğŸ’¬ Received chat request: {request.message[:50]}...")
        
        # ç”Ÿæˆå¯¹è¯IDï¼ˆå¦‚æœæœªæä¾›ï¼‰
        conversation_id = request.conversation_id or str(uuid.uuid4())

        refined_query = await llm_service.generate_refine_query(
            request.message, 0.1, 1024)
        
        # 1. ä½¿ç”¨å¤æ‚æ£€ç´¢æœåŠ¡è¿›è¡Œä¿¡æ¯æ£€ç´¢
        retrieval_result = await complex_retrieval_service.search(
            query=refined_query,
            top_k=10,
            milvus_weight=0.6,  # Milvuså‘é‡æ£€ç´¢æƒé‡
            elasticsearch_weight=0.4,  # Elasticsearchå…³é”®å­—æ£€ç´¢æƒé‡
            use_reranking=True  # å¯ç”¨é‡æ’åº
        )
        
        similar_docs = retrieval_result.documents
        logger.info(f"ğŸ” Found {len(similar_docs)} relevant documents using complex retrieval")
        logger.info(f"ğŸ“Š Retrieval stats: {retrieval_result.metadata}")
        
        # 3. æ„å»ºå¯¹è¯å†å²ï¼ˆå¦‚æœæä¾›ï¼‰
        conversation_history = None
        if request.context:
            conversation_history = [
                {"role": msg.role.value, "content": msg.content}
                for msg in request.context
            ]
        
        # 4. ä½¿ç”¨ LLM ç”Ÿæˆå›å¤
        try:
            response_content = await llm_service.generate_rag_response(
                query=request.message,
                context_docs=similar_docs,
                conversation_history=conversation_history
            )
        except Exception as llm_error:
            logger.error(f"âŒ LLM service failed: {llm_error}")
            # å¦‚æœLLMå¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            response_content = f"æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯ä¿¡æ¯ï¼š{str(llm_error)}"
        
        # 5. æ„å»ºå“åº”
        response = ChatResponse(
            message_id=str(uuid.uuid4()),
            content=response_content,
            conversation_id=conversation_id,
            timestamp=datetime.utcnow(),
            sources=[
                {
                    "title": doc.get("file_path", "unknown"),
                    "doc_id": doc.get("id", "unknown"),
                    "content": doc.get("content", "unknown"),
                    "url": doc.get("metadata", {}).get("url", ""),
                    "score": doc.get("combined_score", doc.get("rerank_score", 0))
                }
                for doc in similar_docs
            ]
        )
        
        logger.info(f"âœ… Chat response generated, length: {len(response_content)}")
        return response
        
    except Exception as e:
        logger.error(f"âŒ Chat processing failed: {e}")
        # è¿”å›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        return ChatResponse(
            message_id=str(uuid.uuid4()),
            content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ã€‚è¯·ç¨åé‡è¯•ã€‚é”™è¯¯ä¿¡æ¯ï¼š{str(e)}",
            conversation_id=request.conversation_id or str(uuid.uuid4()),
            timestamp=datetime.utcnow(),
            sources=[],
            metadata={'error': True, 'error_message': str(e)}
        )


@router.post("/stream")
async def chat_stream(
    request: ChatRequest,
    complex_retrieval_service: ComplexRetrievalService = Depends(get_complex_retrieval_service),
    llm_service: LLMService = Depends(get_llm_service)
):
    """
    æµå¼èŠå¤©å›å¤
    """
    try:
        logger.info(f"ğŸ’¬ Received streaming chat request: {request.message[:50]}...")
        
        # ç”Ÿæˆå¯¹è¯IDï¼ˆå¦‚æœæœªæä¾›ï¼‰
        conversation_id = request.conversation_id or str(uuid.uuid4())
        
        # ä¼˜åŒ–æŸ¥è¯¢ä»¥æé«˜æ£€ç´¢è´¨é‡
        refined_query = await llm_service.generate_refine_query(
            request.message, 0.1, 1024)
        
        # 1. ä½¿ç”¨å¤æ‚æ£€ç´¢æœåŠ¡è¿›è¡Œä¿¡æ¯æ£€ç´¢
        retrieval_result = await complex_retrieval_service.search(
            query=refined_query,
            top_k=10,
            milvus_weight=0.6,  # Milvuså‘é‡æ£€ç´¢æƒé‡
            elasticsearch_weight=0.4,  # Elasticsearchå…³é”®å­—æ£€ç´¢æƒé‡
            use_reranking=True  # å¯ç”¨é‡æ’åº
        )
        
        similar_docs = retrieval_result.documents
        logger.info(f"ğŸ” Found {len(similar_docs)} relevant documents using complex retrieval")
        logger.info(f"ğŸ“Š Retrieval stats: {retrieval_result.metadata}")
        
        # 3. æ„å»ºå¯¹è¯å†å²ï¼ˆå¦‚æœæä¾›ï¼‰
        conversation_history = None
        if request.context:
            conversation_history = [
                {"role": msg.role.value, "content": msg.content}
                for msg in request.context
            ]
        
        # 4. ä½¿ç”¨ LLM ç”Ÿæˆæµå¼å›å¤
        async def generate_stream():
            try:
                # æ„å»ºç³»ç»Ÿæç¤º
                system_prompt = llm_service._build_system_prompt()
                
                # æ„å»ºä¸Šä¸‹æ–‡
                context_text = llm_service._build_context_text(similar_docs)
                
                # æ„å»ºç”¨æˆ·æ¶ˆæ¯
                user_message = llm_service._build_user_message(request.message, context_text)
                
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                messages = [{"role": "system", "content": system_prompt}]
                
                # æ·»åŠ å¯¹è¯å†å²
                if conversation_history:
                    messages.extend(conversation_history)
                
                # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
                messages.append({"role": "user", "content": user_message})
                
                # æµå¼ç”Ÿæˆå›å¤
                async for chunk in llm_service._generate_stream_response(
                    messages, request.temperature or 0.7, request.max_tokens or 4096
                ):
                    yield f"data: {chunk}\n\n"
                
                # å‘é€ç»“æŸæ ‡è®°
                yield "data: [DONE]\n\n"
                
            except Exception as e:
                logger.error(f"âŒ Streaming generation failed: {e}")
                yield f"data: Error: {str(e)}\n\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/plain",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "text/event-stream"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ Streaming chat processing failed: {e}")
        raise HTTPException(status_code=500, detail=f"Streaming chat processing failed: {str(e)}")


@router.get("/history", response_model=ChatHistoryResponse)
async def get_chat_history(
    page: int = 1,
    size: int = 20,
    conversation_id: Optional[str] = None
):
    """
    è·å–èŠå¤©å†å²
    """
    try:
        # TODO: å®ç°ä»æ•°æ®åº“è·å–èŠå¤©å†å²çš„é€»è¾‘
        # è¿™é‡Œæš‚æ—¶è¿”å›ç©ºç»“æœ
        logger.info(f"ğŸ“š Getting chat history, page: {page}, size: {size}")
        
        return ChatHistoryResponse(
            conversations=[],
            total=0,
            page=page,
            size=size
        )
        
    except Exception as e:
        logger.error(f"âŒ Failed to get chat history: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get chat history: {str(e)}")


@router.delete("/history/{conversation_id}")
async def delete_conversation(conversation_id: str):
    """
    åˆ é™¤æŒ‡å®šå¯¹è¯
    """
    try:
        # TODO: å®ç°åˆ é™¤å¯¹è¯çš„é€»è¾‘
        logger.info(f"ğŸ—‘ï¸ Deleting conversation: {conversation_id}")
        
        return {"message": "Conversation deleted successfully", "conversation_id": conversation_id}
        
    except Exception as e:
        logger.error(f"âŒ Failed to delete conversation: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to delete conversation: {str(e)}")
